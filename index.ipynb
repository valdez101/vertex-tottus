{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019ec804-ada7-4037-afcb-b75927ef7ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tottus-413614'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d5a2ad-909f-4585-a417-73384fed82e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://tottus-413623-pipeline'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET_NAME =\"gs://\" + 'tottus-413623' + \"-pipeline\"\n",
    "BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ede949-bbd5-4d60-bb8c-95596ba06dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_14233/3938565504.py:5: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  from kfp.v2.dsl import pipeline, component, Artifact, Dataset, Input, Metrics, Model, Output, InputPath, OutputPath\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from kfp import compiler, dsl\n",
    "from kfp.v2.dsl import pipeline, component, Artifact, Dataset, Input, Metrics, Model, Output, InputPath, OutputPath\n",
    "from typing import Optional\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "from google.cloud import aiplatform_v1\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71a469b-741d-4b78-8325-6999cc98e1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from kfp import compiler, dsl\n",
    "from kfp.v2.dsl import pipeline, component, Artifact, Dataset, Input, Metrics, Model, Output, InputPath, OutputPath\n",
    "from typing import Optional\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "from google.cloud import aiplatform_v1\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876f6d63-d209-40a6-a054-63e266378068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://tottus-413623-pipeline/pipeline_root/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH =%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-east1\"\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "794da490-2246-4042-b8df-9b256f619c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"pandas\", \"pyarrow\", \"scikit-learn\"],\n",
    "    base_image =\"python:3.10\",\n",
    "    output_component_file=\"dataset_creating_1.yaml\"\n",
    ")\n",
    "\n",
    "def get_data_from_bq(\n",
    "    output_data_path: OutputPath(\"Dataset\"),\n",
    "    bq_table: Optional[str] = None\n",
    "):\n",
    "    \n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import load_iris\n",
    "\n",
    "    \n",
    "    if bq_table is not None:\n",
    "        print(\"¡Atención! Este componente no utiliza la tabla de BigQuery proporcionada.\")\n",
    "        print(\"Se cargará el conjunto de datos Iris y se escribirá en un archivo CSV.\")\n",
    "    \n",
    "    # Cargar el conjunto de datos Iris\n",
    "    iris = load_iris()\n",
    "    X, Y = iris.data, iris.target\n",
    "\n",
    "    # Crear un DataFrame de Pandas con las características y las etiquetas\n",
    "    df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "    df['target'] = Y\n",
    "    \n",
    "    df.to_csv(output_data_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ce6342-2430-4977-b8ea-29d7fb9ddcb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"scikit-learn\", \"pandas\", \"joblib\", \"scikit-learn\"],\n",
    "    base_image=\"python:3.10\",\n",
    "    output_component_file=\"model_training.yaml\",\n",
    ")\n",
    "def training_classmod(\n",
    "    data: Input[Dataset],\n",
    "    metrics: Output[Metrics],\n",
    "    model: Output[Model],\n",
    "    predictions: OutputPath(\"Dataset\")\n",
    "):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from joblib import dump\n",
    "    from sklearn.datasets import load_iris\n",
    "    \n",
    "    iris = load_iris()\n",
    "    data_encoded=pd.read_csv(data.path)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_encoded[iris.feature_names], data_encoded['target'],test_size = 0.3)\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred=dt.predict(X_test)\n",
    "    score=dt.score(X_test, y_test)\n",
    "    print('accuracy is:', score)\n",
    "    \n",
    "    metrics.log_metric(\"accuracy\", (score*100.0))\n",
    "    metrics.log_metric(\"model\", \"Tree Class\")\n",
    "    \n",
    "    predictions_df = pd.DataFrame({'predicted': y_pred})\n",
    "    predictions_df.to_csv(predictions, index=False)\n",
    "    \n",
    "    dump(dt, model.path + \".joblib\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d05c01c1-4eef-4255-b891-53e69cd9b8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    "    base_image=\"python:3.10\",\n",
    "    output_component_file=\"model_deployment.yaml\",\n",
    ")\n",
    "def model_deployment(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    import os\n",
    "    model_uri = os.path.dirname(model.uri) + '/'\n",
    "    print(model_uri)\n",
    "    aiplatform.init(project=project, location=region)\n",
    "    \n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"custom-model-pipeline\",\n",
    "        artifact_uri=model_uri,\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest\"\n",
    "    )\n",
    "    endpoint=deployed_model.deploy(machine_type=\"n1-standard-8\", min_replica_count=1)\n",
    "    \n",
    "    vertex_endpoint.uri= endpoint.resource_name\n",
    "    vertex_model.uri=deployed_model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "062d9d49-b7b9-46c6-bf40-5019aa702842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    name=\"custom-pipeline\",\n",
    ")\n",
    "def pipeline(\n",
    "    bq_table: str =\"\",\n",
    "    output_data_path: str=\"data.csv\",\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    # Tarea para obtener los datos de BigQuery\n",
    "    dataset_task = get_data_from_bq(bq_table=bq_table)\n",
    "    \n",
    "    # Tarea para entrenar el modelo, calcular predicciones y guardarlas\n",
    "    training_task = training_classmod(data=dataset_task.output)\n",
    "        \n",
    "    # Tarea para implementar/deploy el modelo\n",
    "    deploy_task = model_deployment(model=training_task.outputs[\"model\"],\n",
    "                                   project=project,\n",
    "                                   region=region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f83aff-3afe-4627-82a2-d286c3d3f331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"custom-pipeline-classifier.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc346433-52c5-4108-aa86-f351c9e7751f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run1 = aiplatform.PipelineJob(\n",
    "    display_name=\"custom-training-vertex-ai-pipeline\",\n",
    "    template_path=\"custom-pipeline-classifier.json\",\n",
    "    job_id=\"custom-pipeline-ef-25\",\n",
    "    enable_caching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5189022-544e-4c49-9e03-19800b8a3650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/601827927420/locations/us-central1/pipelineJobs/custom-pipeline-ef-24\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/601827927420/locations/us-central1/pipelineJobs/custom-pipeline-ef-24')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/custom-pipeline-ef-24?project=601827927420\n"
     ]
    }
   ],
   "source": [
    "run1.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e395580-075f-43b4-9b39-f6283791046c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
